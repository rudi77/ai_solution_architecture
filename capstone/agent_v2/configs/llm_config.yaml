# LLM Service Configuration
# This file defines model aliases, parameters, retry policies, and provider settings

default_model: "main"

models:
  main: "gpt-4.1"
  fast: "gpt-4.1-mini"
  powerful: "gpt-5"
  powerful-1: "gpt-5-1"
  legacy: "gpt-4-turbo"

model_params:
  gpt-4:
    temperature: 0.7
    top_p: 1.0
    max_tokens: 2000
    frequency_penalty: 0.0
    presence_penalty: 0.0
  
  gpt-4.1:
    temperature: 0.2
    top_p: 1.0
    max_tokens: 2000
  
  gpt-4.1-mini:
    temperature: 0.7
    max_tokens: 1500
  
  gpt-5:
    effort: "medium"
    reasoning: "balanced"
    max_tokens: 4000

  gpt-5-1:
    effort: "low"
    reasoning: "minimal"
    max_tokens: 4000    

default_params:
  temperature: 0.7
  max_tokens: 2000
  top_p: 1.0
  frequency_penalty: 0.0
  presence_penalty: 0.0

retry_policy:
  max_attempts: 3
  backoff_multiplier: 2
  timeout: 30
  retry_on_errors:
    - "RateLimitError"
    - "APIConnectionError"
    - "Timeout"
    - "BadRequestError"

providers:
  openai:
    api_key_env: "OPENAI_API_KEY"
    organization_env: "OPENAI_ORG_ID"
    base_url: null
  
  # Azure OpenAI Provider Configuration (Optional)
  # Enable this section to use Azure OpenAI instead of or alongside OpenAI
  azure:
    enabled: false  # Set to true to enable Azure OpenAI
    
    # Environment variable names for Azure credentials
    api_key_env: "AZURE_OPENAI_API_KEY"
    endpoint_url_env: "AZURE_OPENAI_ENDPOINT"
    
    # Azure API version (e.g., "2024-02-15-preview")
    api_version: "2024-02-15-preview"
    
    # Map model aliases to Azure deployment names
    # deployment_mapping:
    #   gpt-4.1: "my-gpt-4-deployment"
    #   gpt-4.1-mini: "my-gpt-4-mini-deployment"
    #   gpt-5: "my-gpt-5-deployment"
    deployment_mapping: {}

logging:
  log_prompts: false
  log_completions: false
  log_token_usage: true
  log_latency: true
  log_parameter_mapping: true

