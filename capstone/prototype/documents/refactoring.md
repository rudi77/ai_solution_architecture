Hier sind die Feature-Request-Dokumente f√ºr die sechs wichtigsten Punkte aus meiner Analyse deines Agenten-Codes. Ich habe sie im √ºblichen **Feature Request Template** aufgeschrieben ‚Äì jeweils mit **Problem Statement**, **Proposed Solution**, **Benefits** und **Acceptance Criteria**.

---

## 1. Migration auf Pydantic v2 (`@field_validator`)

**Problem Statement**
Aktuell werden noch `@validator`-Dekoratoren genutzt. Diese sind seit Pydantic v2 deprecated und erzeugen Warnungen im Log. K√ºnftig werden sie entfernt, was den Agenten brechen w√ºrde.

**Proposed Solution**

* Alle `@validator` durch `@field_validator(..., mode="before")` ersetzen.
* Mapping-Logik (`_map_old_names`) entsprechend migrieren.

**Benefits**

* Zukunftssichere Codebasis (kompatibel mit Pydantic v3).
* Keine st√∂renden Deprecation-Warnungen mehr.

**Acceptance Criteria**

* Keine Pydantic-Deprecation-Warnungen im Log.
* Unit Tests laufen ohne √Ñnderungen durch.
* Verhalten der Validierung ist identisch wie zuvor.

---

## 2. Tool-Metriken erfassen (Zeit, Erfolg, Fehler)

**Problem Statement**
Prometheus-Metriken `tool_execution_time`, `tool_success_rate`, `tool_failure_rate` sind zwar definiert, werden aber nicht inkrementiert/observiert. Damit fehlen Einblicke in Tool-Performance und Fehlerh√§ufigkeit.

**Proposed Solution**

* Im `_handle_tool` bzw. `execute_tool_by_name`:

  * Startzeit messen, Laufzeit in `tool_execution_time` eintragen.
  * Bei Erfolg `tool_success_rate.inc()` erh√∂hen.
  * Bei Fehler `tool_failure_rate.inc()` erh√∂hen.

**Benefits**

* Transparente Tool-Observability.
* Fr√ºhzeitige Erkennung fehlerhafter Tools.
* Basis f√ºr SLAs und Optimierungen.

**Acceptance Criteria**

* Jede Tool-Ausf√ºhrung erzeugt einen Eintrag in den Prometheus-Metriken.
* Erfolge/Fehler sind korrekt gez√§hlt.
* Laufzeiten sind im Histogram sichtbar.

---

## 3. Konsistente Tool-Namen (Lookup-Index)

**Problem Statement**
Toolnamen werden an verschiedenen Stellen normalisiert (`lower().replace("-", "_")`). Dabei kann es zu Inkonsistenzen kommen, sodass vorhandene Tools nicht gefunden werden.

**Proposed Solution**

* Beim Laden der Tools einmalig einen Lookup-Index erstellen: `{normalized_name -> ToolSpec}`.
* Alle weiteren Tool-Calls nur √ºber diesen Index aufl√∂sen.

**Benefits**

* Stabile Zuordnung von Tool-Namen.
* Keine ‚ÄûTool not found‚Äú-Fehler mehr.
* Einfachere Debugbarkeit.

**Acceptance Criteria**

* Tools mit `-`, `_` oder Leerzeichen werden zuverl√§ssig gefunden.
* Kein Unterschied mehr zwischen verschiedenen Normalisierungen.
* Bestehende Tests laufen durch.

---

Super ‚Äî ich erg√§nze den Feature Request zu **Punkt 4 (Strukturierte Task-Repr√§sentation)** mit allen Details zur LLM-Rolle, JSON-Schema, Renderlogik und Ablauf.

---

## 4. Strukturierte Task-Repr√§sentation (statt Markdown-Manipulation)

**Problem Statement**
Aktuell werden Tasks und Status√§nderungen direkt per LLM in einer Markdown-Datei ge√§ndert. Das ist fehleranf√§llig: das LLM kann Aufgaben falsch parsen, falsche Statuswerte einsetzen oder gar den gesamten Plan √ºberschreiben. Dadurch sind Zustand und Darstellung unzuverl√§ssig.

---

**Proposed Solution**

1. **LLM bleibt Planner**

   * Das LLM erzeugt den initialen Plan **nicht als Markdown**, sondern als **valide JSON-Struktur** nach einem festen Schema.
   * Prompting erfolgt mit `generate_structured_response` / Function-Calling, `temperature‚âà0.2` und klarem JSON-Schema.
   * Das LLM liefert zus√§tzlich `open_questions` f√ºr unklare Eingaben.

2. **JSON-Schema f√ºr Tasks und Fragen**

```json
{
  "type": "object",
  "properties": {
    "tasks": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["id", "title", "status"],
        "properties": {
          "id": { "type": "string" },
          "title": { "type": "string" },
          "description": { "type": "string" },
          "tool": { "type": "string" },
          "params": { "type": "object" },
          "status": { "type": "string", "enum": ["PENDING","IN_PROGRESS","COMPLETED","FAILED","SKIPPED"] },
          "depends_on": { "type": "array", "items": { "type": "string" } },
          "priority": { "type": "integer" },
          "notes": { "type": "string" }
        }
      }
    },
    "open_questions": { "type": "array", "items": { "type": "string" } }
  },
  "required": ["tasks","open_questions"],
  "additionalProperties": false
}
```

**Beispieloutput vom LLM:**

```json
{
  "tasks": [
    {
      "id": "t1",
      "title": "Rechnungs-PDFs einlesen",
      "tool": "load_invoices",
      "params": {"path": "/data/invoices"},
      "status": "PENDING",
      "priority": 1
    },
    {
      "id": "t2",
      "title": "Merkmale extrahieren",
      "tool": "extract_features",
      "params": {"model": "gpt-4.1-mini"},
      "status": "PENDING",
      "depends_on": ["t1"],
      "priority": 2
    }
  ],
  "open_questions": [
    "Wo liegen die PDFs? (z. B. /data/invoices)",
    "Welches Zielformat f√ºr den Export? (CSV, Parquet)"
  ]
}
```

3. **Validierung & Reparatur**

   * JSON gegen Schema pr√ºfen.
   * Falls ung√ºltig ‚Üí kurzer Repair-Prompt an das LLM mit Parserfehler.
   * Nach 1‚Äì2 Versuchen ‚Üí `ASK_USER`.

4. **Persistenz im Agent**

   * `context["tasks"]` = Single Source of Truth (Liste von Dicts oder Pydantic-`Task`-Objekten).
   * `context["open_questions"]` = separate Liste.
   * Jede Status√§nderung (z. B. Tool gestartet ‚Üí `IN_PROGRESS`, erfolgreich ‚Üí `COMPLETED`) erfolgt deterministisch im Code.

5. **Renderschicht (Markdown)**

   * Aus den Tasks wird Markdown generiert (View).
   * Status√§nderungen updaten nur `tasks` ‚Üí Markdown wird neu gerendert.
   * **Keine** LLM-Edits am Markdown mehr.

6. **Bei Tool Calls**

   * Passenden Task mit `tool == name` und `status==PENDING/IN_PROGRESS` finden.
   * Status auf `IN_PROGRESS` setzen.
   * Nach Erfolg/Fehler ‚Üí Status `COMPLETED`/`FAILED`, Resultat speichern.

7. **Plan-Updates**

   * Wenn Nutzer neue Antworten liefert oder ein Tool-Fehler neue Informationen verlangt, darf das LLM den Plan erneut generieren (mit aktuellem Plan + neuen Infos als Input).
   * Der Agent merged deterministisch (IDs beibehalten, neue IDs generieren).


**Benefits**

* Robuste, testbare Zustandsf√ºhrung.
* Markdown ist reine Pr√§sentationsschicht, kein kritischer Speicher.
* Keine Halluzinationen beim Statuswechsel.
* Einfaches Debugging: `context["tasks"]` zeigt immer den aktuellen Stand.


**Acceptance Criteria**

* Initialer Plan wird ausschlie√ülich als JSON erzeugt.
* `context["tasks"]` ist die einzige Quelle f√ºr den Taskstatus.
* Markdown ist jederzeit konsistent mit `tasks`.
* Statuswechsel/Resultate sind deterministisch und nachvollziehbar im Log.
* Ung√ºltiges JSON wird repariert oder f√ºhrt zu `ASK_USER`.

---

## 5. Retry-Strategie mit Fehlerklassifizierung

**Problem Statement**
Aktuell wird jede Exception in `_exec_with_retry` automatisch erneut ausgef√ºhrt, egal ob es sich um einen transienten Fehler oder um einen Benutzerfehler handelt.

**Proposed Solution**

* Fehlerarten unterscheiden:

  * `TransientError` ‚Üí Retry mit Backoff.
  * `UserInputError` ‚Üí sofort `ASK_USER`.
* Exceptions entsprechend taggen/werfen.

**Benefits**

* Weniger unn√∂tige Retries.
* Bessere User Experience: Nutzer wird direkt gefragt, wenn Input fehlt/falsch ist.
* Schnellere Recovery bei echten Fehlern.

**Acceptance Criteria**

* Transiente Fehler werden retried.
* User Input Fehler f√ºhren zu einer `ASK_USER`-Aktion.
* Fehlerhandling ist in den Logs nachvollziehbar.

---

## 6. Loop-Guard gegen ‚Äûim Kreis drehen‚Äú

**Problem Statement**
Der Agent kann in Loops geraten, wenn die letzten Aktionen/Observationen keine Fortschritte bringen. Dadurch dreht er sich im Kreis.

**Proposed Solution**

* Loop-Guard implementieren:

  * Wenn die letzten N Aktionen identisch oder wirkungslos waren ‚Üí Abbruch.
  * Stattdessen automatische Aktion `ERROR_RECOVERY` oder `ASK_USER`.

**Benefits**

* Verhindert Endlosschleifen.
* Nutzer erh√§lt klare R√ºckmeldung statt ewiger Wiederholung.
* Stabileres Verhalten in unklaren Situationen.

**Acceptance Criteria**

* Agent bricht ab, wenn 3 gleiche Observations/Aktionen hintereinander auftreten.
* Nutzer wird mit `ASK_USER` konfrontiert.
* Keine Endlosschleifen mehr im Log.

---

üëâ Soll ich dir diese Feature Requests als **ein zusammenh√§ngendes Dokument** (z. B. in Markdown oder DOCX) aufbereiten, damit du sie direkt ins Repo legen kannst?
