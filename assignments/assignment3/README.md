# ğŸ«€ Heart Disease Data Preparation (Assignment 3)

This project performs data cleansing, feature engineering, and MLflow-logged modeling on the [Heart Failure Prediction dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction).

## ğŸ“ Project Structure

```
assignment3_heart_disease/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ heart.csv                  # Dataset from Kaggle, downloaded from [Kaggle-Heart-Failure-Prediction-Dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_prep_heart.ipynb      # Main notebook for data prep and MLflow logging
â”œâ”€â”€ docker-compose.yml             # MLflow Tracking Server
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ mlflow/
    â””â”€â”€ mlruns/                    # MLflow experiment data
```

## ğŸ³ Running MLflow with Docker

Start MLflow Tracking UI locally:

```bash
docker-compose up -d
```

Then access MLflow UI at: [http://localhost:5000](http://localhost:5000)

## ğŸš€ Getting Started

1. Download the dataset from [Kaggle](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction) and place it in `data/heart.csv`
2. Create a virtual environment (e.g. with `uv venv -p 3.11`)
3. Install dependencies:

```bash
uv pip install -r requirements.txt
```

4. Run the notebook:

```bash
jupyter notebook notebooks/data_prep_heart.ipynb
```

## âœ… Highlights

- Handles missing values and duplicate rows
- Feature engineering: age binning, one-hot encoding
- MLflow logging of metrics and trained model
